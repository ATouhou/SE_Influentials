import glob
import os
import json
import sys
import csv
from collections import defaultdict

excl = {}
exclude = open('top200.csv','r')
csvex = csv.reader(exclude,delimiter='\t')
for row in csvex:
	excl[row[0]] = 1
	

users = defaultdict(lambda: { 'followers': 0 })

for f in glob.glob('twitter-users/*.json'):
    data = json.load(file(f))
    screen_name = data['screen_name']
    users[screen_name] = { 'followers': data['followers_count'] }



def process_follower_list(screen_name, edges=[], depth=0, max_depth=2):
    f = os.path.join('following', screen_name + '.csv')

    if not os.path.exists(f):
        return edges

    followers = [line.strip().split('\t') for line in file(f)]

    for follower_data in followers:
        if len(follower_data) < 2:
            continue

        screen_name_2 = follower_data[1]

        # use the number of followers for screen_name as the weight
        weight = users[screen_name]['followers']

	x = 0	
	y = 1
	if excl.has_key(screen_name_2):
        	edges.append([screen_name,x, screen_name_2,y])
	else:
		continue


    return edges


exclude1 = open('top200.csv','r')
csvex1 = csv.reader(exclude1,delimiter='\t')
for row in csvex1:
	SEED = row[0]
	edges = process_follower_list(SEED, max_depth=200)

with open('twitter_network.csv', 'w') as outf:
    edge_exists = {}
    for edge in edges:
        key = ','.join([str(x) for x in edge])
        if not(key in edge_exists):
            outf.write('"%s","%d","%s","%d"\n' % (edge[0], edge[1], edge[2], edge[3]))
            edge_exists[key] = True


